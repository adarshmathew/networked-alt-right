19/11/29 17:17:11 INFO SparkContext: Running Spark version 2.1.0
19/11/29 17:17:12 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
19/11/29 17:17:12 WARN SparkConf: In Spark 1.0 and later spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone and LOCAL_DIRS in YARN).
19/11/29 17:17:12 INFO SecurityManager: Changing view acls to: Mathew
19/11/29 17:17:12 INFO SecurityManager: Changing modify acls to: Mathew
19/11/29 17:17:12 INFO SecurityManager: Changing view acls groups to: 
19/11/29 17:17:12 INFO SecurityManager: Changing modify acls groups to: 
19/11/29 17:17:12 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Mathew); groups with view permissions: Set(); users  with modify permissions: Set(Mathew); groups with modify permissions: Set()
19/11/29 17:17:12 INFO Utils: Successfully started service 'sparkDriver' on port 56431.
19/11/29 17:17:12 INFO SparkEnv: Registering MapOutputTracker
19/11/29 17:17:12 INFO SparkEnv: Registering BlockManagerMaster
19/11/29 17:17:12 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
19/11/29 17:17:12 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
19/11/29 17:17:12 INFO DiskBlockManager: Created local directory at C:\Users\Mathew\AppData\Local\spark\spark-2.1.0-bin-hadoop2.7\tmp\local\blockmgr-25faf196-66f1-4faf-b7d5-afb41864321c
19/11/29 17:17:12 INFO MemoryStore: MemoryStore started with capacity 413.9 MB
19/11/29 17:17:12 INFO SparkEnv: Registering OutputCommitCoordinator
19/11/29 17:17:12 INFO Utils: Successfully started service 'SparkUI' on port 4040.
19/11/29 17:17:12 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4040
19/11/29 17:17:12 INFO SparkContext: Added JAR file:/C:/Users/Mathew/Documents/R/win-library/3.6/sparklyr/java/sparklyr-2.0-2.11.jar at spark://127.0.0.1:56431/jars/sparklyr-2.0-2.11.jar with timestamp 1575069432530
19/11/29 17:17:12 INFO Executor: Starting executor ID driver on host localhost
19/11/29 17:17:12 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 56472.
19/11/29 17:17:12 INFO NettyBlockTransferService: Server created on 127.0.0.1:56472
19/11/29 17:17:12 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
19/11/29 17:17:12 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 56472, None)
19/11/29 17:17:12 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:56472 with 413.9 MB RAM, BlockManagerId(driver, 127.0.0.1, 56472, None)
19/11/29 17:17:12 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 56472, None)
19/11/29 17:17:12 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 56472, None)
19/11/29 17:17:12 INFO SharedState: Warehouse path is 'C:/Users/Mathew/AppData/Local/spark/spark-2.1.0-bin-hadoop2.7/tmp/hive'.
19/11/29 17:17:13 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/11/29 17:17:14 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/11/29 17:17:28 INFO SparkContext: Invoking stop() from shutdown hook
19/11/29 17:17:28 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4040
19/11/29 17:17:28 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
19/11/29 17:17:28 INFO MemoryStore: MemoryStore cleared
19/11/29 17:17:28 INFO BlockManager: BlockManager stopped
19/11/29 17:17:28 INFO BlockManagerMaster: BlockManagerMaster stopped
19/11/29 17:17:28 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
19/11/29 17:17:28 INFO SparkContext: Successfully stopped SparkContext
19/11/29 17:17:28 INFO ShutdownHookManager: Shutdown hook called
19/11/29 17:17:28 INFO ShutdownHookManager: Deleting directory C:\Users\Mathew\AppData\Local\spark\spark-2.1.0-bin-hadoop2.7\tmp\local\spark-41f48542-7c14-4331-b43c-35874e37045d
19/11/29 21:39:07 INFO SparkContext: Running Spark version 2.1.0
19/11/29 21:39:07 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
19/11/29 21:39:07 WARN SparkConf: In Spark 1.0 and later spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone and LOCAL_DIRS in YARN).
19/11/29 21:39:07 INFO SecurityManager: Changing view acls to: Mathew
19/11/29 21:39:07 INFO SecurityManager: Changing modify acls to: Mathew
19/11/29 21:39:07 INFO SecurityManager: Changing view acls groups to: 
19/11/29 21:39:07 INFO SecurityManager: Changing modify acls groups to: 
19/11/29 21:39:07 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Mathew); groups with view permissions: Set(); users  with modify permissions: Set(Mathew); groups with modify permissions: Set()
19/11/29 21:39:08 INFO Utils: Successfully started service 'sparkDriver' on port 61648.
19/11/29 21:39:08 INFO SparkEnv: Registering MapOutputTracker
19/11/29 21:39:08 INFO SparkEnv: Registering BlockManagerMaster
19/11/29 21:39:08 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
19/11/29 21:39:08 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
19/11/29 21:39:08 INFO DiskBlockManager: Created local directory at C:\Users\Mathew\AppData\Local\spark\spark-2.1.0-bin-hadoop2.7\tmp\local\blockmgr-013185bc-81c6-4a99-80c1-3be28b6e6530
19/11/29 21:39:08 INFO MemoryStore: MemoryStore started with capacity 413.9 MB
19/11/29 21:39:08 INFO SparkEnv: Registering OutputCommitCoordinator
19/11/29 21:39:08 INFO Utils: Successfully started service 'SparkUI' on port 4040.
19/11/29 21:39:08 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4040
19/11/29 21:39:08 INFO SparkContext: Added JAR file:/C:/Users/Mathew/Documents/R/win-library/3.6/sparklyr/java/sparklyr-2.0-2.11.jar at spark://127.0.0.1:61648/jars/sparklyr-2.0-2.11.jar with timestamp 1575085148244
19/11/29 21:39:08 INFO Executor: Starting executor ID driver on host localhost
19/11/29 21:39:08 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 61689.
19/11/29 21:39:08 INFO NettyBlockTransferService: Server created on 127.0.0.1:61689
19/11/29 21:39:08 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
19/11/29 21:39:08 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 61689, None)
19/11/29 21:39:08 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:61689 with 413.9 MB RAM, BlockManagerId(driver, 127.0.0.1, 61689, None)
19/11/29 21:39:08 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 61689, None)
19/11/29 21:39:08 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 61689, None)
19/11/29 21:39:08 INFO SharedState: Warehouse path is 'C:/Users/Mathew/AppData/Local/spark/spark-2.1.0-bin-hadoop2.7/tmp/hive'.
19/11/29 21:39:08 INFO SparkSqlParser: Parsing command: SHOW TABLES
